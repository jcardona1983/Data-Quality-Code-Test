{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a72287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas_in_blore.xlsx\r\n",
      "Data_Quality_Engineer_Code_Test__(1).pdf\r\n",
      "Prueba Inclusion.ipynb\r\n",
      "data_file_20210527182730 copy.csv\r\n",
      "data_file_20210527182730.csv\r\n",
      "data_file_20210528182554.csv\r\n",
      "data_file_20210528182844.csv\r\n",
      "helper_functions.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c27e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install validators\n",
    "#!pip install phonenumbers\n",
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109f1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from helper_functions import is_zero_file, validate_url, empty_string, validate_phone\n",
    "from helper_functions import strip_character, search_character, unique_list\n",
    "\n",
    "# installed libraries\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107ea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files(path):\n",
    "    \"\"\"Checks if there is any file in the path...\n",
    "       \n",
    "       Input Arguments: path - path where the files arrive.  \n",
    "    \"\"\"\n",
    "    print('\\n','***Looking for new files...','\\n')\n",
    "    \n",
    "    file_paths = []\n",
    "    \n",
    "    # get all files matching extension from directory\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        files = glob.glob(os.path.join(root,'*.csv'))\n",
    "        for f in files :\n",
    "            file_paths.append(os.path.abspath(f))\n",
    "\n",
    "    # get total number of files found\n",
    "    num_files = len(file_paths)\n",
    "    print('{} files found in {}'.format(num_files, path))\n",
    "    print('\\n'.join(map(str, file_paths)))\n",
    "    \n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def is_file_loaded(filepath):\n",
    "    \"\"\"Checks if a file path is in the log_file.txt\n",
    "       \n",
    "       Input Arguments: filepath - path of a file \n",
    "    \"\"\"        \n",
    "    # creates the file if it doesn't exist\n",
    "    f = open(\"log_file.txt\", \"a+\")\n",
    "    f.seek(0)\n",
    "    lines = f.read().split('\\n')\n",
    "    f.close()\n",
    "    \n",
    "    processed_files = pd.Series(lines)\n",
    "    res = sum(processed_files.isin([filepath]))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def log_processed_files(filePathList):\n",
    "    \"\"\"Saves the paths of the loaded files in a txt file.\n",
    "       \n",
    "       Input Arguments: filePathList - paths of the loaded files \n",
    "    \"\"\"\n",
    "    f = open(\"log_file.txt\", \"a\")\n",
    "    \n",
    "    for path in filePathList:\n",
    "        f.write(path+'\\n')\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "\n",
    "def validate_files(filepath):\n",
    "    \"\"\"Checks if a file is empty or if the file was previously loaded\n",
    "       I'm assuming that each file has a different name, so I'll not \n",
    "       load a file if it has the same name as a file already loaded\n",
    "       \n",
    "       Input Arguments: filepath - file to be checked or validated \n",
    "    \"\"\"\n",
    "\n",
    "    load_file = True\n",
    "    \n",
    "    if is_zero_file(filepath):\n",
    "        print('Empty file found!!! ignoring file...','\\n')\n",
    "        load_file = False\n",
    "    \n",
    "    if is_file_loaded(filepath):\n",
    "        print('File already loaded!!! ignoring file...','\\n')\n",
    "        load_file = False\n",
    "        \n",
    "    return load_file\n",
    "        \n",
    "    \n",
    "def load_files(filepaths):\n",
    "    \"\"\"Loads the files found in the check_files function\n",
    "       \n",
    "       Input Arguments: filepaths - paths of the existing files.  \n",
    "    \"\"\"\n",
    "    print('\\n','***Loading files...','\\n')\n",
    "    \n",
    "    cols = ['url', 'address', 'name', 'rate', 'votes', 'phone', 'location', \n",
    "            'rest_type', 'dish_liked', 'cuisines', 'reviews_list']\n",
    "    df = pd.DataFrame()\n",
    "    n = 0\n",
    "    processed_files = []\n",
    "    \n",
    "    for path in filepaths:\n",
    "        print(f'Loading file: {path}','\\n')\n",
    "        \n",
    "        if validate_files(path):\n",
    "            df_temp = pd.read_csv(path, usecols = cols)\n",
    "            df = pd.concat([df, df_temp])\n",
    "            print(f'{len(df_temp)} rows loaded!!!','\\n')\n",
    "            n = n + 1\n",
    "            processed_files.append(path)\n",
    "            \n",
    "    # resets index to start from 0\n",
    "    df = df.reset_index(drop = True)\n",
    "    # replaces nan for '' to handle null as empty strings\n",
    "    df = df.replace(np.nan, '', regex = True)\n",
    "            \n",
    "    # save processed files in a metadata file.\n",
    "    log_processed_files(processed_files)\n",
    "    \n",
    "    print(f'***{n} files were loaded','\\n')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def cleaning_cols(df):\n",
    "    \"\"\"Identifies and Cleans the errors in each column of the dataframe\n",
    "       \n",
    "       Input Arguments: df - data frame with data loaded from the files\n",
    "    \"\"\"\n",
    "    print('\\n','***Cleaning Data...','\\n')\n",
    "    re_str = r'[^a-zA-Z \\\\!@#$%&*_+-=|\\:\"<>,./()[\\]{}\\']'\n",
    "    re_rate = r\"[^0-5+\\.0-9+/0-5+|NEW]\"\n",
    "    \n",
    "    print('* Checking Url Column','\\n')\n",
    "    temp = df['url'].apply(validate_url)\n",
    "    url_ind_list = temp[temp == False].index.to_list()\n",
    "    print(f'Rows with errors in Url: {len(url_ind_list)}','\\n')\n",
    "    \n",
    "    print('* Checking Address Column','\\n')\n",
    "    temp2 = df['address'].apply(search_character, reg = re_str)\n",
    "    address_ind_list = temp2[temp2.notna()].index.to_list()\n",
    "    print(f'Rows with errors in Address: {len(address_ind_list)}','\\n')\n",
    "\n",
    "    print('-> Cleaning Address...','\\n')\n",
    "    df['address'] = df['address'].apply(strip_character, reg = re_str)\n",
    "    \n",
    "    print('* Checking Name Column','\\n')\n",
    "    temp3 = df['name'].apply(search_character, reg = re_str)\n",
    "    name_ind_list = temp3[temp3.notna()].index.to_list()\n",
    "    name_nan_rows = df[df['name'] == ''].index.to_list()\n",
    "    \n",
    "    print(f'Rows with null values in name: {len(name_nan_rows)}','\\n')\n",
    "    print(f'Rows with errors in Name: {len(name_ind_list)}','\\n')\n",
    "    \n",
    "    print('-> Cleaning Name...','\\n')\n",
    "    df['name'] = df['name'].apply(strip_character, reg = re_str)\n",
    "    \n",
    "    print('* Checking Rate Column','\\n')\n",
    "    temp4 = df['rate'].apply(search_character, reg = re_rate)\n",
    "    rate_ind_list = temp4[temp4.notna()].index.to_list()\n",
    "    print(f'Rows with errors in Rate: {len(rate_ind_list)}','\\n')\n",
    "    \n",
    "    print('-> Cleaning Rate...','\\n')\n",
    "    df['rate'] = df['rate'].apply(strip_character, reg = re_rate)\n",
    "    \n",
    "    print('* Checking Phone Column','\\n')\n",
    "    df[['phone1','phone2']] = df['phone'].str.split('[\\\\r|\\\\n]{1,}', n=1, expand = True)\n",
    "    # replacing + and whitespaces\n",
    "    df['phone1'] = df['phone1'].str.replace('[\\s\\+]','', regex = True)\n",
    "    df['phone2'] = df['phone2'].str.replace('[\\s\\+]','', regex = True)\n",
    "    print('* Phone column was slipt into columns: Phone1 & Phone2','\\n')\n",
    "    \n",
    "    # checking valid phone numbers\n",
    "    temp5 = df['phone1'].apply(validate_phone)\n",
    "    phone_ind_list = temp5[temp5 == False].index.to_list()\n",
    "    temp6 = df['phone2'].apply(validate_phone)\n",
    "    phone_ind_list2 = temp6[temp6 == False].index.to_list()\n",
    "    \n",
    "    # checking null values\n",
    "    temp7 = df.apply(lambda x: empty_string(x['phone1']) & empty_string(x['phone2']), axis = 1)\n",
    "    phone_nan_rows = temp7[temp7 == True].index.to_list()\n",
    "    # transform phone from string to numeric\n",
    "    df['phone1'] = pd.to_numeric(df['phone1'].str.replace('na|n','',regex = True))\n",
    "    df['phone2'] = pd.to_numeric(df['phone2'].str.replace('na|n','',regex = True))\n",
    "    # dropping phone column\n",
    "    df = df.drop('phone', axis=1)\n",
    "    \n",
    "    print(f'Rows with null values in Phone: {len(phone_nan_rows)}','\\n')\n",
    "    print(f'Rows with errors in Phone1: {len(phone_ind_list)}','\\n')\n",
    "    print(f'Rows with errors in Phone2: {len(phone_ind_list2)}','\\n')\n",
    "    \n",
    "    print('* Checking Location Column','\\n')\n",
    "    # splitting location into 2 columns, because some records have a street included in the area. \n",
    "    df[['loc1','loc2']] = df['location'].str.split(',', n=1, expand = True)\n",
    "    # extracting the area from the split columns\n",
    "    df['area'] = df.apply(lambda x: x['loc1'] if empty_string(x['loc2']) else x['loc2'].replace(' ',''), axis = 1)\n",
    "    \n",
    "    df_locations =  pd.read_excel('Areas_in_Blore.xlsx')\n",
    "    \n",
    "    # looking up the area in the Areas_in_Blore.xlsx file\n",
    "    temp8 = df['area'].isin(df_locations['Area'])\n",
    "    loc_ind_list = temp8[temp8 == False].index.to_list()\n",
    "    \n",
    "    # checking null values\n",
    "    temp9 = df['location'].apply(empty_string)\n",
    "    loc_nan_rows = temp9[temp9 == True].index.to_list()\n",
    "    \n",
    "    # dropping columns\n",
    "    df = df.drop(['loc1','loc2','area'], axis=1)\n",
    "    \n",
    "    print(f'Rows with null values in Location: {len(loc_nan_rows)}','\\n')\n",
    "    print(f'Rows not found in Areas_in_Blore.xlsx: {len(loc_ind_list)}','\\n')\n",
    "    \n",
    "    bad_row_list = url_ind_list + address_ind_list + name_ind_list + name_nan_rows \\\n",
    "                   + rate_ind_list + phone_ind_list + phone_ind_list2 + phone_nan_rows \\\n",
    "                   + loc_ind_list + loc_nan_rows\n",
    "    \n",
    "    with open(\"metadata.bad\", \"w\") as f:\n",
    "        f.write(\"Type_of_issue,\"+'Row_num_list'+'\\n')\n",
    "        f.write(\"Invalid url,\"+' '.join([str(item) for item in url_ind_list])+'\\n')\n",
    "        f.write(\"Address with junk characters,\"+' '.join([str(item) for item in address_ind_list])+'\\n')\n",
    "        f.write(\"Name with junk characters,\"+' '.join([str(item) for item in name_ind_list])+'\\n')\n",
    "        f.write(\"Name with null values,\"+' '.join([str(item) for item in name_nan_rows])+'\\n')\n",
    "        f.write(\"Rate with spaces or - char,\"+' '.join([str(item) for item in rate_ind_list])+'\\n')\n",
    "        f.write(\"Invalid Phone1,\"+' '.join([str(item) for item in phone_ind_list])+'\\n')\n",
    "        f.write(\"Invalid Phone2,\"+' '.join([str(item) for item in phone_ind_list2])+'\\n')\n",
    "        f.write(\"Phones with null values,\"+' '.join([str(item) for item in phone_nan_rows])+'\\n')\n",
    "        f.write(\"Incorrect location,\"+' '.join([str(item) for item in loc_ind_list])+'\\n')\n",
    "        f.write(\"Location with null values,\"+' '.join([str(item) for item in loc_nan_rows])+'\\n')\n",
    "        \n",
    "    return df, bad_row_list\n",
    "\n",
    "\n",
    "def create_outfile(df, bad_list):\n",
    "    \"\"\"Capture all the clean records and save them in log.out file\n",
    "       \n",
    "       Input Arguments: bad_list - bad records index list\n",
    "    \"\"\"\n",
    "    print('\\n','***Saving clean records in log.out file...','\\n')\n",
    "    lst = unique_list(bad_list)\n",
    "    \n",
    "    if len(lst) > 0:\n",
    "        df_clean = df[~df.index.isin(lst)]\n",
    "        df_clean.to_csv(\"log.out\")\n",
    "        \n",
    "    print(f'Clean Rows loaded: {len(df_clean)}','\\n')\n",
    "        \n",
    "        \n",
    "def create_badfile(df, bad_list):\n",
    "    \"\"\"Capture all the bad records and save them in log.bad file\n",
    "       \n",
    "       Input Arguments: bad_list - bad records index list\n",
    "    \"\"\"\n",
    "    print('\\n','***Saving bad records in log.bad file...','\\n')\n",
    "    lst = unique_list(bad_list)\n",
    "    \n",
    "    if len(lst) > 0:\n",
    "        df_bad = df[df.index.isin(lst)]\n",
    "        df_bad.to_csv(\"log.bad\")\n",
    "        \n",
    "    print(f'Bad Rows loaded: {len(df_bad)}','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875bd1a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Pipeline Started!\n",
      "****************************************\n",
      "\n",
      " ***Looking for new files... \n",
      "\n",
      "4 files found in ./\n",
      "/Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210528182554.csv\n",
      "/Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210527182730 copy.csv\n",
      "/Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210528182844.csv\n",
      "/Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210527182730.csv\n",
      "\n",
      " ***Loading files... \n",
      "\n",
      "Loading file: /Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210528182554.csv \n",
      "\n",
      "7378 rows loaded!!! \n",
      "\n",
      "Loading file: /Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210527182730 copy.csv \n",
      "\n",
      "Empty file found!!! ignoring file... \n",
      "\n",
      "Loading file: /Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210528182844.csv \n",
      "\n",
      "7379 rows loaded!!! \n",
      "\n",
      "Loading file: /Users/jorge.rivas/Desktop/Prueba Tecnica Inclusion/data_file_20210527182730.csv \n",
      "\n",
      "7379 rows loaded!!! \n",
      "\n",
      "***3 files were loaded \n",
      "\n",
      "\n",
      " ***Cleaning Data... \n",
      "\n",
      "* Checking Url Column \n",
      "\n",
      "Rows with errors in Url: 2 \n",
      "\n",
      "* Checking Address Column \n",
      "\n",
      "Rows with errors in Address: 25 \n",
      "\n",
      "-> Cleaning Address... \n",
      "\n",
      "* Checking Name Column \n",
      "\n",
      "Rows with null values in name: 1 \n",
      "\n",
      "Rows with errors in Name: 149 \n",
      "\n",
      "-> Cleaning Name... \n",
      "\n",
      "* Checking Rate Column \n",
      "\n",
      "Rows with errors in Rate: 462 \n",
      "\n",
      "-> Cleaning Rate... \n",
      "\n",
      "* Checking Phone Column \n",
      "\n",
      "* Phone column was slipt into columns: Phone1 & Phone2 \n",
      "\n",
      "Rows with null values in Phone: 263 \n",
      "\n",
      "Rows with errors in Phone1: 5555 \n",
      "\n",
      "Rows with errors in Phone2: 3589 \n",
      "\n",
      "* Checking Location Column \n",
      "\n",
      "Rows with null values in Location: 4 \n",
      "\n",
      "Rows not found in Areas_in_Blore.xlsx: 13904 \n",
      "\n",
      "\n",
      " ***Saving clean records in log.out file... \n",
      "\n",
      "Clean Rows loaded: 4562 \n",
      "\n",
      "\n",
      " ***Saving bad records in log.bad file... \n",
      "\n",
      "Bad Rows loaded: 17574 \n",
      "\n",
      "****************************************\n",
      "Pipeline Ended!\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    print('****************************************')\n",
    "    print('Pipeline Started!')\n",
    "    print('****************************************')\n",
    "    \n",
    "    # checks if there are files to load\n",
    "    filepaths = check_files(path = './')\n",
    "    \n",
    "    # loads existing files data into the df Data Frame\n",
    "    if(len(filepaths) > 0):\n",
    "        df = load_files(filepaths)\n",
    "        # validates each column of df\n",
    "        df, bad_row_list = cleaning_cols(df)\n",
    "        # saves clean records\n",
    "        create_outfile(df, bad_row_list)\n",
    "        # saves bad records\n",
    "        create_badfile(df, bad_row_list)\n",
    "        \n",
    "    print('****************************************')\n",
    "    print('Pipeline Ended!')\n",
    "    print('****************************************')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed430823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas_in_blore.xlsx\r\n",
      "Data_Quality_Engineer_Code_Test__(1).pdf\r\n",
      "Prueba Inclusion.ipynb\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "data_file_20210527182730 copy.csv\r\n",
      "data_file_20210527182730.csv\r\n",
      "data_file_20210528182554.csv\r\n",
      "data_file_20210528182844.csv\r\n",
      "helper_functions.py\r\n",
      "log.bad\r\n",
      "log.out\r\n",
      "log_file.txt\r\n",
      "metadata.bad\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e75b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
